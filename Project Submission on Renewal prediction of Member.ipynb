{"nbformat_minor": 1, "cells": [{"source": "# <center> Predicting the renewal Prediction of the member<\\center> \n    ", "cell_type": "markdown", "metadata": {}}, {"source": "## <Center> By Jayanthi Elumalai <br>30-June-2019 </Center>\n", "cell_type": "markdown", "metadata": {}}, {"source": "## 1.Introduction", "cell_type": "markdown", "metadata": {}}, {"source": "### 1.1 Background", "cell_type": "markdown", "metadata": {}}, {"source": "    As I have worked in more healthcare industry for 10 years , I have choosen this problem, where the Heath Insurance company always want to know the member renewal rate and how much to charge member according to the rules provided by the goverment. Members will renew the policy every year (Covering only the Individula policy whoes having the default pricing for family member till 5 and if the members of the family is more than 5 then Premium will get  increased accordingly.  ", "cell_type": "markdown", "metadata": {}}, {"source": "### 1.2 Problem ", "cell_type": "markdown", "metadata": {}}, {"source": "    To identify whether a member will renew the policy for next year or not using the hisorical of his transaction and with similarities in other members", "cell_type": "markdown", "metadata": {}}, {"source": "### 1.3 Interest", "cell_type": "markdown", "metadata": {}}, {"source": "    Of course the Health Insurance company always interested to know about the members count who will be renewed for next year and with analysis they can give some input to underwritters who can define the plan according to the member interest", "cell_type": "markdown", "metadata": {}}, {"source": "# 2. Data acquisition and cleaning\n", "cell_type": "markdown", "metadata": {}}, {"source": "## 2.1 Data sources", "cell_type": "markdown", "metadata": {}}, {"source": "    I have used the one of the data sources from Kaggle for Healthcare insurance (insurance.csv)and added few more features to it according to the need of the problem statement \n    Source <https://www.kaggle.com/annetxu/health-insurance-cost-prediction>", "cell_type": "markdown", "metadata": {}}, {"source": "### 2.2 Data Cleaning", "cell_type": "markdown", "metadata": {}}, {"source": "    Data is take from one CSV file and I have added some values randomly to it intialy to the data set. Hence if some thing is irrelevant during the coding we will redo the cleaning process accordingly , as the initial phase there is no need of cleaning process.\n       \n   **Items which is cleaned as part of data cleaning**\n       \n       . Policy detail and meber details joined together and retrieved the data\n       . Corporate\\Small group policy where grouped together and removed from the data set , since this prediction if only for the individual policy.            . Member ID , DOB , SSN and other Secured information should be removed before tranfering the data from the DB.\n       . Member Name and dependent name Policy Number is not needed for creating a Machine Learning model hence removed those.\n       . Plan, Region and county and some other fields where categorical so need to change those using Label encoding and One Hot encoder\n    \n    After fixing these problems, I checked for outliers in the data. I found there were some extreme outliers, mostly caused by some types of small sample size problem. Example : Member is very new and he is not having any renewal before.", "cell_type": "markdown", "metadata": {}}, {"source": "### 2.3 Feature selection", "cell_type": "markdown", "metadata": {}}, {"source": " There were 1339 and 9 features in the data set ,\n \n **Features which is selected for Modeling**\n Age, Member count of each policy, plan details, State, county, Premium, Payperiod, Original Joined date and end Date.\n \n \n **Feature which is dropped**\n \n       . Policy detail and meber details joined together and retrieved the data\n       . Corporate\\Small group policy where grouped together and removed from the data set , since this prediction if only for the individual policy.            . Member ID , DOB , SSN and other Secured information should be removed before tranfering the data from the DB.\n       . Member Name and dependent name Policy Number is not needed for creating a Machine Learning model hence removed those.      \n    \n ", "cell_type": "markdown", "metadata": {}}, {"source": "## 3. Exploratory Data Analysis\n", "cell_type": "markdown", "metadata": {}}, {"source": "**Note Below are in enhancement phase , I will submitt the remaining in the Next assignment** ", "cell_type": "markdown", "metadata": {}}, {"source": "", "cell_type": "markdown", "metadata": {}}, {"source": "", "cell_type": "markdown", "metadata": {}}, {"source": "", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# Using Multi Linear regression ", "cell_type": "markdown", "metadata": {}}, {"source": "import numpy as np\nimport pandas as pd\nimport matplotlib as plt", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "!conda install -c conda-forge statsmodels --yes", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Solving environment: done\n\n# All requested packages already installed.\n\n"}], "execution_count": 2}, {"source": "import statsmodels as sta", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 4}, {"source": "File =  \"https://eu-gb.dataplatform.cloud.ibm.com/projects/553cfdcc-5856-44a6-92e9-08d057ddf02d/data-assets/insurance.csv\"\ndataset = pd.read_csv(file)\n\ndataset.shape()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "error", "evalue": "name 'file' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-17-53ed1f4eff48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mFile\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m\"https://eu-gb.dataplatform.cloud.ibm.com/projects/553cfdcc-5856-44a6-92e9-08d057ddf02d/data-assets/insurance.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mNameError\u001b[0m: name 'file' is not defined"], "ename": "NameError"}], "execution_count": 17}, {"source": "dataset.describe()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "dataset.head()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "dataset.tail()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "dataset.isnull().sum()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "X=dataset.iloc[:,:-1].values # assign all the fields except the last which is label or predictor\nY=dataset.iloc[:,4].values # all rows with only last column", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# Preprocessing (as part of EDA)\nfrom sklearn.processing import LabelEncoder, OneHotEncoder\nle_x = LabelEncoder() # need to check if we have plan name have the \nX[:,4:5] = le_x.fit_transform(X[:, 4:5])\n\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "ohe_x = OneHotEncoder(Categorical_features = [5])\nX = ohe_x.fit_transform(X.toarray()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "\n# Dummy Variable Trap\nX= X[:,1:] # need to change the dummy variable trap for which field is changed\n\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "#split dataset into training and test \nfrom Sklearn_model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.30, random_state = 0)\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "#Building a Model\nfrom sklearn.linear_Model from LinearRegression\nregress = LinearRegression()\nregress.fit(x_train, y_train)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# Prediction using the x_test data to check the model build\ny_pred = regress.predict(x_test)\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# Checking the accuracy using the score function for train data and test data\nregress.score (x_train, y_train)\nregress.score (x_train, y_train)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# Stats Model library to generate Linear regression with more statistical data\n#Trying to data the constant value 1 to all the rows (X= C+ X)\nimport statsmodel.formula.api as sm\nX= np.append(arr=np.ones(shape = (row, col), values = x, dtype = int))\n\n# iteration 1\nX_ov = x[:,[0,1,2,3,4,5]]\n\nregress_ols = sm.OLS(endog=Y,exog =X_ov).fit()\nregress_ols.summary()\n\nX_ovc = x_ov[:,1:]\nx_ov_train, y_ov_train, x_ov_test, y_ov_test = train_test_split(X_ovc, Y, test_size = 0.30, randomstat = 0)\n                                                               \nregress_ov1= LinearRegression()\nregress_ov1.fit(x_ov_train, y_ov_train)\nregress_ov1.score(x_ov_train, y_ov_train)\nregress_ov1.score( x_ov_test, y_ov_test)\n\n\n\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "#After checking the values P_values from Summary we have to remove the fields which is greater 0.05 (SL)\n\n# iteration 2\nX_ov = x[:,[0,1,2,3,4,5]]\n\nregress_ols = sm.OLS(endog=Y,exog =X_ov).fit()\nregress_ols.summary()\n\nX_ovc = x_ov[:,1:]\nx_ov_train, y_ov_train, x_ov_test, y_ov_test = train_test_split(X_ovc, Y, test_size = 0.30, randomstat = 0)\n                                                               \nregress_ov1= LinearRegression()\nregress_ov1.fit(x_ov_train, y_ov_train)\nregress_ov1.score(x_ov_train, y_ov_train)\nregress_ov1.score( x_ov_test, y_ov_test)\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# iteration 1\nX_ov = x[:,[0,1,2,3,4,5]]\n\nregress_ols = sm.OLS(endog=Y,exog =X_ov).fit()\nregress_ols.summary()\n\nX_ovc = x_ov[:,1:]\nx_ov_train, y_ov_train, x_ov_test, y_ov_test = train_test_split(X_ovc, Y, test_size = 0.30, randomstat = 0)\n                                                               \nregress_ov1= LinearRegression()\nregress_ov1.fit(x_ov_train, y_ov_train)\nregress_ov1.score(x_ov_train, y_ov_train)\nregress_ov1.score( x_ov_test, y_ov_test)\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# iteration 1\nX_ov = x[:,[0,1,2,3,4,5]]\n\nregress_ols = sm.OLS(endog=Y,exog =X_ov).fit()\nregress_ols.summary()\n\nX_ovc = x_ov[:,1:]\nx_ov_train, y_ov_train, x_ov_test, y_ov_test = train_test_split(X_ovc, Y, test_size = 0.30, randomstat = 0)\n                                                               \nregress_ov1= LinearRegression()\nregress_ov1.fit(x_ov_train, y_ov_train)\nregress_ov1.score(x_ov_train, y_ov_train)\nregress_ov1.score( x_ov_test, y_ov_test)\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3.5", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.5", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}